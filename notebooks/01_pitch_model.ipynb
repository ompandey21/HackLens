{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f33a133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Basic imports ready, folders ok.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: imports + utilities\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "import joblib\n",
    "\n",
    "# ML imports (we'll import SBERT and LightGBM later inside try/except)\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create required folders if not present\n",
    "os.makedirs(\"data/pitches\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Basic imports ready, folders ok.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e5d624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created: C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\\HackLens.pptx\n",
      "‚úÖ Created: C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\\SmartApp.pptx\n",
      "‚úÖ Created: C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\\HealthTech.pptx\n",
      "‚úÖ Created: C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\\AgriAI.pptx\n",
      "‚úÖ Created: C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\\EduAI.pptx\n",
      "‚úÖ Created: C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\\FinTechX.pptx\n",
      "‚úÖ Created: C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\\GreenTech.pptx\n",
      "‚úÖ Created: C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\\MediAssist.pptx\n",
      "‚úÖ Created: C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\\RoboHelper.pptx\n",
      "‚úÖ Created: C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\\CyberSafe.pptx\n",
      "üéâ All dummy PPTs recreated successfully!\n"
     ]
    }
   ],
   "source": [
    "from pptx import Presentation\n",
    "import os\n",
    "\n",
    "def create_dummy_ppt(path, project_name, problem, solution, tech, demo, future):\n",
    "    prs = Presentation()\n",
    "\n",
    "    # Title slide\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[0])\n",
    "    slide.shapes.title.text = project_name\n",
    "    slide.placeholders[1].text = \"Hackathon Pitch Deck\"\n",
    "\n",
    "    # Problem slide\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "    slide.shapes.title.text = \"Problem\"\n",
    "    slide.placeholders[1].text = problem\n",
    "\n",
    "    # Solution slide\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "    slide.shapes.title.text = \"Solution\"\n",
    "    slide.placeholders[1].text = solution\n",
    "\n",
    "    # Tech Stack slide\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "    slide.shapes.title.text = \"Tech Stack\"\n",
    "    slide.placeholders[1].text = tech\n",
    "\n",
    "    # Demo slide\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "    slide.shapes.title.text = \"Demo / Prototype\"\n",
    "    slide.placeholders[1].text = demo\n",
    "\n",
    "    # Future Scope slide\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "    slide.shapes.title.text = \"Future Scope\"\n",
    "    slide.placeholders[1].text = future\n",
    "\n",
    "    prs.save(path)\n",
    "    print(f\"‚úÖ Created: {path}\")\n",
    "\n",
    "\n",
    "# üìÅ Folder where PPTs will be stored\n",
    "os.makedirs(r\"C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\", exist_ok=True)\n",
    "\n",
    "# üéØ Create 10 sample projects\n",
    "projects = [\n",
    "    (\"HackLens\", \"Hackathon judging is slow\", \"AI-based automatic judging\", \"Python, FastAPI, LightGBM\", \"Basic working prototype\", \"Add AI for code evaluation\"),\n",
    "    (\"SmartApp\", \"People forget meds\", \"Reminder app with AI schedule\", \"Python, Flutter, MongoDB\", \"Prototype tested\", \"Integrate with smartwatch\"),\n",
    "    (\"HealthTech\", \"Rural patients lack doctors\", \"Telemedicine + AI triage\", \"React, Node, TensorFlow\", \"Working demo\", \"Add multilingual support\"),\n",
    "    (\"AgriAI\", \"Low crop yield due to poor soil\", \"Soil health prediction model\", \"Python, Scikit-learn, IoT sensors\", \"Demo tested on farms\", \"Scale to nationwide data\"),\n",
    "    (\"EduAI\", \"Students need adaptive learning\", \"Personalized course engine\", \"FastAPI, PyTorch, NLP\", \"Prototype with course data\", \"Add real-time progress tracking\"),\n",
    "    (\"FinTechX\", \"SMEs lack credit access\", \"AI-based credit scoring\", \"Python, Pandas, LightGBM\", \"Prototype with financial data\", \"Expand dataset\"),\n",
    "    (\"GreenTech\", \"Waste management inefficiency\", \"IoT-based smart bins\", \"Python, IoT sensors\", \"Route demo ready\", \"Pilot deployment in cities\"),\n",
    "    (\"MediAssist\", \"Doctors lack automated notes\", \"Voice-to-text assistant\", \"Python, Whisper, NLP\", \"Functional prototype\", \"Add hospital integrations\"),\n",
    "    (\"RoboHelper\", \"Home chores automation\", \"Mini robot for household help\", \"ROS, Python\", \"Demo robot built\", \"Add speech commands\"),\n",
    "    (\"CyberSafe\", \"Phishing attacks on SMBs\", \"Email threat detection system\", \"Python, ML, Flask\", \"Detection demo ready\", \"Improve accuracy & add dashboard\"),\n",
    "]\n",
    "\n",
    "# Generate the PPTs\n",
    "for name, problem, solution, tech, demo, future in projects:\n",
    "    path = fr\"C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\\{name}.pptx\"\n",
    "    create_dummy_ppt(path, name, problem, solution, tech, demo, future)\n",
    "\n",
    "print(\"üéâ All dummy PPTs recreated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bad43e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Loading SBERT model (this may take a few seconds)...\n",
      "‚úÖ SBERT model loaded!\n",
      "‚úÖ Dataset created successfully!\n",
      "Shape: (10, 395)\n",
      "          filename  judge_score\n",
      "0      AgriAI.pptx          6.5\n",
      "1   CyberSafe.pptx          8.8\n",
      "2       EduAI.pptx          7.5\n",
      "3    FinTechX.pptx          8.0\n",
      "4   GreenTech.pptx          6.0\n",
      "5    HackLens.pptx          8.5\n",
      "6  HealthTech.pptx          9.0\n",
      "7  MediAssist.pptx          9.5\n",
      "8  RoboHelper.pptx          5.5\n",
      "9    SmartApp.pptx          7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pptx import Presentation\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import textstat\n",
    "\n",
    "# --- Load the sentence transformer model ---\n",
    "print(\"‚è≥ Loading SBERT model (this may take a few seconds)...\")\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"‚úÖ SBERT model loaded!\")\n",
    "\n",
    "# --- Define feature extractor ---\n",
    "def extract_features_from_ppt(path):\n",
    "    prs = Presentation(path)\n",
    "    slide_count = len(prs.slides)\n",
    "\n",
    "    all_text = []\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if hasattr(shape, \"text\") and shape.text.strip():\n",
    "                all_text.append(shape.text.strip())\n",
    "    joined_text = \" \".join(all_text)\n",
    "\n",
    "    # --- Basic text stats ---\n",
    "    word_count = len(joined_text.split())\n",
    "    avg_words_per_slide = word_count / slide_count if slide_count else 0\n",
    "    readability = textstat.flesch_reading_ease(joined_text)\n",
    "\n",
    "    # --- Keyword flags ---\n",
    "    keywords = {\n",
    "        \"has_problem\": int(bool(re.search(r\"problem\", joined_text, re.I))),\n",
    "        \"has_solution\": int(bool(re.search(r\"solution\", joined_text, re.I))),\n",
    "        \"has_tech\": int(bool(re.search(r\"tech|technology|stack\", joined_text, re.I))),\n",
    "        \"has_future\": int(bool(re.search(r\"future|scope|next\", joined_text, re.I))),\n",
    "        \"has_demo\": int(bool(re.search(r\"demo|prototype|working\", joined_text, re.I))),\n",
    "    }\n",
    "\n",
    "    # --- Embeddings ---\n",
    "    embedding = sbert.encode(joined_text)\n",
    "\n",
    "    # --- Combine all features into one list ---\n",
    "    features = [\n",
    "        slide_count, word_count, avg_words_per_slide, readability,\n",
    "        keywords[\"has_problem\"], keywords[\"has_solution\"], keywords[\"has_tech\"],\n",
    "        keywords[\"has_future\"], keywords[\"has_demo\"]\n",
    "    ] + embedding.tolist()\n",
    "\n",
    "    return features\n",
    "\n",
    "# --- Build dataset ---\n",
    "folder = r\"C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\data\\pitches\"\n",
    "labels = {\n",
    "    \"HackLens.pptx\": 8.5,\n",
    "    \"SmartApp.pptx\": 7.0,\n",
    "    \"HealthTech.pptx\": 9.0,\n",
    "    \"AgriAI.pptx\": 6.5,\n",
    "    \"EduAI.pptx\": 7.5,\n",
    "    \"FinTechX.pptx\": 8.0,\n",
    "    \"GreenTech.pptx\": 6.0,\n",
    "    \"MediAssist.pptx\": 9.5,\n",
    "    \"RoboHelper.pptx\": 5.5,\n",
    "    \"CyberSafe.pptx\": 8.8\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for fname in os.listdir(folder):\n",
    "    if fname.endswith(\".pptx\"):\n",
    "        path = os.path.join(folder, fname)\n",
    "        feats = extract_features_from_ppt(path)\n",
    "        rows.append([fname] + feats + [labels[fname]])\n",
    "\n",
    "cols = [\"filename\", \"slide_count\", \"word_count\", \"avg_words_per_slide\", \"readability\",\n",
    "        \"has_problem\", \"has_solution\", \"has_tech\", \"has_future\", \"has_demo\"] + \\\n",
    "       [f\"emb_{i}\" for i in range(384)] + [\"judge_score\"]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "print(\"‚úÖ Dataset created successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df[[\"filename\", \"judge_score\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de26d360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training data ready ‚Äî Shape: (10, 393)\n",
      "üìä Split: 7 train / 3 test samples\n",
      "üöÄ Training LightGBM model...\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's rmse: 1.06799\tvalid_1's rmse: 1.54507\n",
      "‚úÖ Model training complete!\n",
      "üìà RMSE on test set: 1.545\n",
      "\n",
      "üîç Predicted vs Actual:\n",
      "RoboHelper.pptx      ‚Üí Predicted: 7.68 | Actual: 5.50\n",
      "CyberSafe.pptx       ‚Üí Predicted: 7.63 | Actual: 8.80\n",
      "HackLens.pptx        ‚Üí Predicted: 7.48 | Actual: 8.50\n",
      "\n",
      "üíæ Model saved successfully at: C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\models\\pitch_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- Step 1: Prepare data ---\n",
    "X = df.drop(columns=[\"filename\", \"judge_score\"])\n",
    "y = df[\"judge_score\"]\n",
    "\n",
    "print(f\"‚úÖ Training data ready ‚Äî Shape: {X.shape}\")\n",
    "\n",
    "# --- Step 2: Handle NaN values (if any) ---\n",
    "if X.isna().sum().sum() > 0:\n",
    "    print(f\"‚ö†Ô∏è Found NaN values: {X.isna().sum().sum()} ‚Äî replacing with 0\")\n",
    "    X = X.fillna(0)\n",
    "\n",
    "# --- Step 3: Train/Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "print(f\"üìä Split: {len(X_train)} train / {len(X_test)} test samples\")\n",
    "\n",
    "# --- Step 4: Create LightGBM datasets ---\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "# --- Step 5: Define Model Parameters ---\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"min_data_in_leaf\": 1,\n",
    "    \"min_data_in_bin\": 1,\n",
    "    \"verbosity\": -1\n",
    "}\n",
    "\n",
    "# --- Step 6: Train the Model ---\n",
    "print(\"üöÄ Training LightGBM model...\")\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    num_boost_round=200,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=20),\n",
    "        lgb.log_evaluation(period=50)\n",
    "    ]\n",
    ")\n",
    "print(\"‚úÖ Model training complete!\")\n",
    "\n",
    "# --- Step 7: Evaluate the Model ---\n",
    "preds = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(f\"üìà RMSE on test set: {rmse:.3f}\")\n",
    "\n",
    "# Compare predicted vs actual\n",
    "results = list(zip(df.loc[X_test.index, \"filename\"], preds, y_test))\n",
    "print(\"\\nüîç Predicted vs Actual:\")\n",
    "for fname, pred, actual in results:\n",
    "    print(f\"{fname:20s} ‚Üí Predicted: {pred:.2f} | Actual: {actual:.2f}\")\n",
    "\n",
    "# --- Step 8: Save the Trained Model ---\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model_path = r\"C:\\Users\\Rachit Upadhyay\\OneDrive\\Desktop\\Mini_Project\\models\\pitch_model.pkl\"\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"\\nüíæ Model saved successfully at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53596a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hacklens_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
